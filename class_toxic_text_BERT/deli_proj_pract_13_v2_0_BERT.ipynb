{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1aeb2d39-282a-4966-b6f2-18d91a8d9525",
   "metadata": {},
   "source": [
    "<font size=6><b>**Я.Практикум. Проект №13**</b></font>\n",
    "    \n",
    "<font size=6><b>**Проект для «Викишоп» с BERT**</b></font>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b88c65-7ddd-4650-9ec5-d4ef6553eb69",
   "metadata": {},
   "source": [
    "# Постановка задачи\n",
    "\n",
    "**Заказчик**  \n",
    "Интернет-магазин «Викишоп»\n",
    "\n",
    "**Цель**  \n",
    "Разработать модель машинного обучения, которая будет искать токсичные комментарии и отправлять их на модерацию.\n",
    "В качестве метрики качества следует использовать F1, значение которой должно быть не менее 0,75.\n",
    "\n",
    "**Задачи**  \n",
    "\n",
    "1. Загрузить и исследовать данные;\n",
    "1. Подготовить три вида признаков:\n",
    "    - очищенный незакодированный текст;\n",
    "    - TF-IDF;\n",
    "    - emedings при помощи модели BERT; \n",
    "1. Обучить на полученных признаках модель логистической регрессии (LR);\n",
    "1. Обучить на очищенном тексте модель CatBoost (CB) классифицировать позитивные и негативные комментарии на разных признаках;\n",
    "1. Используя метрику ROC-AUC определить лучшее сочетание модели и признаков;\n",
    "1. Для лучшей модели выбрать оптимальный порог (threshold) по критерию максимизации значения метрики F1;  \n",
    "1. Сделать выводы.\n",
    "\n",
    "**Исходные данные**  \n",
    "Набор данных с разметкой о токсичности правок."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fe090c-0ef3-49d3-a946-76ca30463ff4",
   "metadata": {},
   "source": [
    "# Подготовка окружения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda639ab-714a-4084-b318-4f25706c7cfa",
   "metadata": {},
   "source": [
    "Загрузим библиотеки, необходимые для выполнения проекта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54304f01-65b9-4f8e-91e2-a3394fce01b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {},
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from pymystem3 import Mystem\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    RandomizedSearchCV,\n",
    "    StratifiedKFold,\n",
    ")\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "try:\n",
    "    from catboost import CatBoostClassifier, Pool, cv\n",
    "except:\n",
    "    !pip install catboost\n",
    "    from catboost import CatBoostClassifier, Pool, cv\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "except:\n",
    "    !pip install torch\n",
    "    import torch\n",
    "\n",
    "try:\n",
    "    import transformers\n",
    "except:\n",
    "    !pip install transformers\n",
    "    import transformers\n",
    "\n",
    "\n",
    "# автоформатирование\n",
    "%load_ext lab_black\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a151f1-4af6-44f6-affa-770e4bf62f44",
   "metadata": {},
   "source": [
    "Загрузим сами данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55fddbab-de3c-4344-950c-25d0a282d9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv(\"D:/jupyter/practicum_13/toxic_comments.csv\")\n",
    "except:\n",
    "    df = pd.read_csv(\"https://code.s3.yandex.net/datasets/toxic_comments.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba628f0-be1c-4173-8444-0c33b9a136ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Обзор данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acd9ad4-1ac4-476e-85e4-c885ada8df17",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "Вызовем первые 5 строк, общую информацию о таблице, а также количество дубликатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4481ca09-9d90-4c47-8dc0-ec0fdc8668d2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {},
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79162f26-5891-4b00-b9c7-5e3caba6fb0a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5df635a0-8086-4c3f-8584-80495a6765bb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {},
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81bd96b-4d47-4f8f-9106-d00d3bfa921a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "Датафрейм содержит 159 571 объекта без пропусков и явных повторений.\n",
    "Каждый объект включает текст комментария `text` и целевой признак `toxic`.\n",
    "При этом, комментарии сделаны на английском языке.\n",
    "\n",
    "Проверим дисбаланс классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a19e0b0d-98cc-4feb-b733-d84f2a77610f",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"toxic\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662331d3-fc54-46ce-befb-6c3adbfe3278",
   "metadata": {},
   "source": [
    "Только 10% данных содержат токсичные комментарии.\n",
    "Такой дисбаланс должен быть учтен при разбиении датафрема на обучающую и тестовую выборки.\n",
    "\n",
    "Рассмотрим детально первую строку с текстом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7a26a5c-2785-4233-8721-5602b63eeebf",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d084bab-5fa7-4f40-a1ad-b2402ed98ed7",
   "metadata": {},
   "source": [
    "Текстовая информация содержит следующие особенности:  \n",
    "* используется различный регистр;\n",
    "* используются скрытые текстовые символы (\\n, \\t...);\n",
    "* используются числовые символы;\n",
    "* используется различная форма слов.\n",
    "\n",
    "Для улучшения значения целевой метрики при подготовке признаков перечисленные недостатки целесообразно устранить."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57203c33-2aa2-4578-80b7-51b93cb9ae7d",
   "metadata": {},
   "source": [
    "# Подготовка признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3db18aa-e12e-433f-8a6e-6975d22836a9",
   "metadata": {},
   "source": [
    "## Очистка текста"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87070cea-df17-4411-80aa-15ad1704ff7d",
   "metadata": {},
   "source": [
    "Проведем обработку строк: очистим их от лишних символов и стоп-слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b61d57e3-d771-4e5f-aa0c-cd794ad0dcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(nltk_stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3874299-c7f6-48f9-bedd-3b1622f38159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear(raw):\n",
    "    text = raw[\"text\"].lower()\n",
    "    text = \" \".join(re.sub(r\"[^a-zA-Z ]\", \" \", text).split())\n",
    "    text = \" \".join([w for w in word_tokenize(text) if not w in stopwords])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9b37697-975b-4dc8-b25d-b33c779bf57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df.apply(clear, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af634a1c-ace6-46e1-b7ee-e7626426a227",
   "metadata": {},
   "source": [
    "Проверим выполнение операции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d31c055-30b9-4f46-b546-43ff7fb75192",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea67fc8-ce81-42a0-b538-d97c91510e9e",
   "metadata": {},
   "source": [
    "Очистка выполнена.\n",
    "Однако при этом могли проявится дубликаты в данных, которые были неявными при первоначальном обзоре."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a28c4cd8-dbd2-43fa-a4c0-3b27bf9edec0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {},
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d91f630-d900-41bf-bf39-5a2e44ce47ec",
   "metadata": {},
   "source": [
    "Количество таких дубликатов составляет около 1%, в результате чего они могут быть безболезненно удалены."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b3fb4a9-8634-4213-8562-2007e58aea3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb4c1774-2ec7-40ba-90a5-f9b4273ad995",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {},
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b670b5-09e4-4dc0-b073-2749aa855c40",
   "metadata": {},
   "source": [
    "Признак с очищенным текстом сформирован, можно переходить к следующему шагу."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ee7631-d672-4e3e-8cf4-acbca97205bf",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea23448-1a71-4523-a7b8-5321bcd13020",
   "metadata": {},
   "source": [
    "Выполним stemming по алгоритму Портера.\n",
    "Полученный указанной обработкой корпус слов сохраним в соответствующий столбец.\n",
    "\n",
    "Для повышения стабильности обработки добавим заполнение корпуса пропуском в случае, если не удается выполнить stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29425e58-dcf4-4a7b-8fec-040fa2800098",
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3720823-fa44-4511-acde-ead16bfbd20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def porterstem(raw):\n",
    "    text = raw[\"text\"]\n",
    "    try:\n",
    "        text = \" \".join([porter.stem(word) for word in text.split()])\n",
    "    except:\n",
    "        text = np.NaN\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c4619d7-a927-437b-b05b-2f584f6fbe21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(feature_name, batch_size, function_name):\n",
    "    df[feature_name] = np.NaN\n",
    "    for i in tqdm(range(df.shape[0] // batch_size)):\n",
    "        df[feature_name][batch_size * i : batch_size * (i + 1)] = df[\n",
    "            batch_size * i : batch_size * (i + 1)\n",
    "        ].apply(function_name, axis=1)\n",
    "\n",
    "    df[feature_name][batch_size * (i + 1) :] = df[batch_size * (i + 1) :].apply(\n",
    "        function_name, axis=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "331f143c-4cfe-4237-a319-b52fde177de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc4e35b19909475991dd07de4f48b44f",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoder(\"corpus\", 10000, porterstem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23c23a0-f32a-43f0-84f0-309c49db256c",
   "metadata": {},
   "source": [
    "Проверим количество пропусков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60d2b1eb-2383-46b2-bdb4-226d097a80d9",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9b5ef3-df69-4fe6-b0b5-81a272f013d1",
   "metadata": {},
   "source": [
    "Один объект не обработался. \n",
    "Выведем строку с ним и содержимое ячейки с комментарием."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83c87195-e6b6-4ead-9c2c-4cd300f7d3c8",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df[\"corpus\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63003284-a3eb-4e0e-8364-97278886ab9d",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df[\"corpus\"].isna()][\"text\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f1d938-a05d-407f-b7b3-ad1d48c0fcd8",
   "metadata": {},
   "source": [
    "По всей видимости, объект - шутка разработчиков задачи.\n",
    "Учитывая, что он не несет смысловой нагрузки, исключим его из рассмотрения. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd4a0607-92c3-4e1e-8b5c-68845229f0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abcb0f9-6ee7-4390-aaab-2a6e51804ae3",
   "metadata": {},
   "source": [
    "Полученный stemming'ом корпус слов используем при определении TF-IDF.\n",
    "Учитывая, что указанный параметр зависит от состава выборки, его определение целесообразно проводить только после разделения датафрейма на обучающую, валидационную и тестовую выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c22d10-0db9-430b-aff4-fe32e6205a4c",
   "metadata": {},
   "source": [
    "## Embeding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81abdb55-886e-4d2a-86a0-a51d8e4b6c53",
   "metadata": {},
   "source": [
    "Инициализируем токенизатор и модель BERT на основе базовой предобученной из стандартной библиотеки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d8ca9a0-4100-4a1d-8f1d-c374e71e40f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer = transformers.DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model_bert = transformers.DistilBertModel.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbe7838-9f8f-47a9-b02a-c4570c16c418",
   "metadata": {},
   "source": [
    "Преобразуем текст в номера токенов из словаря методом encode.\n",
    "Учитывая, что выбранная модель BERT предобучена на текстах длинной 512 слов, добавим соответствующий параметр в метод encode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "03af544f-28f6-4e88-95f1-8ed22b0f7b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_token(raw):\n",
    "    text = raw[\"text\"]\n",
    "    try:\n",
    "        text = tokenizer.encode(text, add_special_tokens=True, max_length=512)\n",
    "    except:\n",
    "        text = np.NaN\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "34022881-0b07-40f8-98e2-658262bd429a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dea3623fb0b4168aead2124206f4c6a",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoder(\"corpus_bert\", 10000, bert_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a36cb1-164c-4d4c-89a6-d24703b83e8e",
   "metadata": {},
   "source": [
    "Проверим количество пропущенных объектов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3921a395-0600-42f6-81ef-335c73aef7bf",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d68e77f-3986-44e5-9406-4dc58ce34821",
   "metadata": {},
   "source": [
    "Для всех объектов успешно созданы токены.\n",
    "\n",
    "Применим метод padding, чтобы уравнять длины исходных текстов в корпусе. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c9a757a5-c902-43e3-a3b8-dc4d5768dac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = np.array([i + [0] * (512 - len(i)) for i in df[\"corpus_bert\"].values])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c40f81-4116-4358-94c5-1c0e567999c1",
   "metadata": {},
   "source": [
    "Отбросим нулевые токены и создадим attention_mask для действительно важных из них. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b3851084-062c-4f6d-a37b-7eff1f923bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4802502c-45df-48e1-946d-48aec3e47aa3",
   "metadata": {},
   "source": [
    "Определим сами embedings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8dc526d9-dd17-4dcd-bf7c-50e04ce49fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def batch_embeder(low_step, high_step):\n",
    "    # преобразуем данные\n",
    "    batch = torch.tensor(padded[low_step:high_step]).to(device)\n",
    "    # преобразуем маску\n",
    "    attention_mask_batch = torch.tensor(attention_mask[low_step:high_step]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model_bert.to(device)\n",
    "        batch_embeddings = model_bert(batch, attention_mask=attention_mask_batch)\n",
    "\n",
    "    # преобразуем элементы методом numpy() к типу numpy.array\n",
    "    return batch_embeddings[0][:, 0, :].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "81a87479-dba6-4774-8094-7e42b8d43470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e7691e1444e4e628cf5f176c456f3a3",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings = []\n",
    "batch_size = 50\n",
    "\n",
    "for i in tqdm(range(padded.shape[0] // batch_size)):\n",
    "    embeddings.append(batch_embeder(batch_size * i, batch_size * (i + 1)))\n",
    "\n",
    "# финальный проход\n",
    "embeddings.append(batch_embeder(batch_size * (i + 1), None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea6aad8-95ba-4437-8166-caaa98d610c7",
   "metadata": {},
   "source": [
    "Соберём все embedings в матрицу признаков вызовом функции concatenate():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "22ea2621-022b-40b2-9e74-e103f52f0642",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_bert = np.concatenate(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04f581a-777e-466d-b981-33342bce0719",
   "metadata": {},
   "source": [
    "Embedings созданы.\n",
    "Можно переходить к разделению датафрейма на подвыборки."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93c3ef7-16db-48ab-a373-e05fc068f08e",
   "metadata": {},
   "source": [
    "## Разделение на подвыборки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42b161d-209a-44fd-9e9e-ce3545b66e60",
   "metadata": {},
   "source": [
    "Разделим данные на подвыборки в пропорции 3:1:1 с сохранением дисбаланса классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9a31ab20-7a05-4ecc-98eb-a5b7982cef89",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_bert, val_test_features_bert, train, val_test = train_test_split(\n",
    "    features_bert, df, test_size=0.4, random_state=26, stratify=df[\"toxic\"]\n",
    ")\n",
    "\n",
    "val_features_bert, test_features_bert, val, test = train_test_split(\n",
    "    val_test_features_bert,\n",
    "    val_test,\n",
    "    test_size=0.5,\n",
    "    random_state=26,\n",
    "    stratify=val_test[\"toxic\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b71e501c-2be9-40fe-bb0b-db3a6f7b6ac9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {},
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"toxic\"].mean(), val[\"toxic\"].mean(), test[\"toxic\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa896e3-d850-4bf6-8967-169b6ea1fa1e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "Дисбаланс сохранен.\n",
    "\n",
    "Теперь необходимо сформировать значения TF-IDF корпуса текстов.\n",
    "Для выполнения вычислений используем соответствующую библиотеку. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9cadc5ac-5705-4066-8fd2-900e61d3d2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)\n",
    "\n",
    "train_tf_idf = count_tf_idf.fit_transform(train[\"corpus\"])\n",
    "val_tf_idf = count_tf_idf.transform(val[\"corpus\"])\n",
    "test_tf_idf = count_tf_idf.transform(test[\"corpus\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b1642e-b543-45b4-8f04-6c7551d2bfa2",
   "metadata": {},
   "source": [
    "Признаки TF-IDF сформированы, можно приступать к моделированию."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7051a36e-6aa1-444d-8763-119ca04e3c26",
   "metadata": {},
   "source": [
    "# Моделирование"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eca7181-9b86-4083-8204-f66f30a3c97b",
   "metadata": {},
   "source": [
    "## Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2517e620-b397-49de-a4f3-a9d0913109c1",
   "metadata": {},
   "source": [
    "Определим модель и проведем ее обучение на двух типах признаков: TF-IDF и BERT embedings.\n",
    "\n",
    "Одним из ключевых гиперпараметров LR является вес классов.\n",
    "В этой связи проведем его подбор при помощи метода случайного поиска."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "182276af-5b27-4980-bd4c-14d49c42c39e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameters = {\"C\": np.linspace(0.0001, 100, 20)}\n",
    "skf = StratifiedKFold(5, shuffle=True, random_state=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "564d6db1-22e2-432d-bf98-67c53cc33a33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {},
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr_tf_idf = RandomizedSearchCV(\n",
    "    estimator=LogisticRegression(max_iter=500, random_state=26, n_jobs=-1),\n",
    "    param_distributions=parameters,\n",
    "    n_jobs=-1,\n",
    "    n_iter=5,\n",
    "    random_state=26,\n",
    ")\n",
    "model_lr_tf_idf.fit(train_tf_idf, train[\"toxic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8ca4a69b-6463-4555-912f-31a5f29f073f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {},
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr_bert = RandomizedSearchCV(\n",
    "    estimator=LogisticRegression(max_iter=500, random_state=26, n_jobs=-1),\n",
    "    param_distributions=parameters,\n",
    "    n_jobs=-1,\n",
    "    cv=skf,\n",
    "    n_iter=5,\n",
    "    random_state=26,\n",
    ")\n",
    "model_lr_bert.fit(train_features_bert, train[\"toxic\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1cb760-bf14-4b30-a969-be88ef6ea57f",
   "metadata": {},
   "source": [
    "Определим значение метрики ROC-AUC на валидационной подвыборке.\n",
    "Указанная метрика не зависит от порога для предсказания класса, в связи с чем ее целесообразно использовать для сравнения разных моделей и определения лучшей из них."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "76df491e-2a61-4a4d-9310-1f21e890164d",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(val[\"toxic\"], model_lr_tf_idf.predict(val_tf_idf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c5209900-0bf7-4313-bdfe-833dc8123f50",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(val[\"toxic\"], model_lr_bert.predict(val_features_bert))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9afca0-8ddf-472e-81f1-5f9699593adc",
   "metadata": {},
   "source": [
    "По полученным значениям видно, что обучение LR на признаках TF-IDF на 3,7% эффективнее обучения на embedings.\n",
    "\n",
    "Проверим качество обучение модели CB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0989440-3001-41e4-b471-85821a2a905c",
   "metadata": {},
   "source": [
    "## Catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de3afab-3481-4c36-9293-e21001eaca53",
   "metadata": {},
   "source": [
    "Модель CB имеет встроенные механизмы формирования embedings.\n",
    "В этой связи ей достаточно передать только очищенный текст, обозначив его соответствующим образом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "abdf957c-60da-4c09-8c0a-50bb3e69a1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pool = Pool(\n",
    "    data=train[[\"corpus\"]],\n",
    "    label=train[\"toxic\"],\n",
    "    feature_names=[\"corpus\"],\n",
    "    text_features=[\"corpus\"],\n",
    ")\n",
    "\n",
    "val_pool = Pool(\n",
    "    data=val[[\"corpus\"]],\n",
    "    label=val[\"toxic\"],\n",
    "    feature_names=[\"corpus\"],\n",
    "    text_features=[\"corpus\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a31e4f6-9c61-4355-86b9-a46b616fcc9e",
   "metadata": {},
   "source": [
    "Обучение модели СВ проведем при помощи встроенного метода кросс-валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7c45ae5b-0338-42df-accd-0567dda120a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "942f9b96d94447efb8fb3a2e85a1ebe3",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time \n",
    "params = {\n",
    "    \"eval_metric\": \"Logloss\",\n",
    "    \"loss_function\": \"Logloss\",\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"random_seed\": 26,\n",
    "    \"verbose\": 250,\n",
    "    'early_stopping_rounds':200,\n",
    "}\n",
    "\n",
    "cv_data = cv(\n",
    "    pool=train_pool,\n",
    "    params=params,\n",
    "    fold_count=5,\n",
    "    shuffle=True,\n",
    "    partition_random_seed=0,\n",
    "    stratified=True,\n",
    "    verbose=False,\n",
    "    early_stopping_rounds=200,\n",
    "    return_models=True,\n",
    "    plot=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38eecd3b-3cc1-426c-aba3-850f40c99620",
   "metadata": {},
   "source": [
    "Лучшая модель получена на фолде с номером 3.\n",
    "Определим для нее метрику ROC-AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "50968217-39db-4937-82db-aa8b6f47cf68",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(val[\"toxic\"], cv_data[1][3].predict(val_pool, prediction_type=\"Class\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd50535-5ecf-4c93-8f22-95fa7f548265",
   "metadata": {},
   "source": [
    "Полученное значение на 0,7% хуже соответствующего, полученного при обучении модели LR на признаках TF-IDF.\n",
    "В этой связи, для полноценного сравнения проведем аналогичное обучение на тех же признаках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b503f8eb-e2d3-4370-a46f-027cc350c983",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pool_tf_idf = Pool(\n",
    "    data=train_tf_idf,\n",
    "    label=train[\"toxic\"],\n",
    ")\n",
    "\n",
    "val_pool_tf_idf = Pool(\n",
    "    data=val_tf_idf,\n",
    "    label=val[\"toxic\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9bdf443c-c2c7-4d3f-bc28-0f7875f6f8b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8cae8c3687f466a82b5bd974ba1413f",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time \n",
    "cv_data_tf_idf = cv(\n",
    "    pool=train_pool_tf_idf,\n",
    "    params=params,\n",
    "    fold_count=5,\n",
    "    shuffle=True,\n",
    "    partition_random_seed=0,\n",
    "    stratified=True,\n",
    "    verbose=False,\n",
    "    early_stopping_rounds=200,\n",
    "    return_models=True,\n",
    "    plot=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "04f71fb2-366f-4a16-9a37-a22ce577d9a3",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(\n",
    "    val[\"toxic\"], cv_data_tf_idf[1][0].predict(val_pool_tf_idf, prediction_type=\"Class\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27308bf-aec7-4efd-aa02-34db1c6f3fcd",
   "metadata": {},
   "source": [
    "Полученное значение хуже полученного при кодировании текста внутренними средствами модели CB.\n",
    "\n",
    "Таким образом, по метрике ROC-AUC на валидационной выборке лучшей из рассмотренных моделей, является модель LR, обученная на признаках TF-IDF.\n",
    "\n",
    "На следующем шаге определим лучшее значение порога для расчета целевой метрики F1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462f247b-3c6c-4ae3-9667-0a9200bdee67",
   "metadata": {},
   "source": [
    "## Выбор порога классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc61e811-5354-44dd-b42a-0d144f077692",
   "metadata": {},
   "source": [
    "Определим значение целевой метрики со стандартным порогом, равным 0,5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7fb6f414-c5c6-44dd-ae97-7c64664c00a1",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(val[\"toxic\"], model_lr_tf_idf.predict(val_tf_idf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04929199-093e-4695-b734-bb03574edb03",
   "metadata": {},
   "source": [
    "Полученное значение выше заданного по условиям задачи критерия 0,75. \n",
    "Учитывая, что на тестовой выборке указанная метрика, скорее всего, изменится в худшую сторону, целесообразно провести анализ  возможности ее улучшения за счет изменения порога классификации.\n",
    "Для этого создадим столбец со значениями вероятности определения к тому или иному классу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5407503c-30da-4006-87e4-83ccfdd8b521",
   "metadata": {},
   "outputs": [],
   "source": [
    "val[\"pred_lr_tf_idf_proba\"] = np.NaN\n",
    "val[\"pred_lr_tf_idf_proba\"] = 1 - model_lr_tf_idf.predict_proba(val_tf_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f29ce6e-71b5-450f-94d0-2eca8075e742",
   "metadata": {},
   "source": [
    "Определим перечень всех существующих значений вероятностей и добавим его к нулевому значению."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b6f83772-b8b6-4609-b1fd-67da7b6fb00a",
   "metadata": {
    "id": "vogYubqPl2k7"
   },
   "outputs": [],
   "source": [
    "thrs = [0] + list(val[\"pred_lr_tf_idf_proba\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212b1631-0154-422c-87e5-80b3d71b3446",
   "metadata": {},
   "source": [
    "Переберем в цикле значения метрики F1 при изменении порога по всем значениям вероятности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8e47133e-34e6-4010-a0fa-9420d9924c06",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "81054d76bd434f7a9072a82a6d1f1f93",
      "d5a8c826756446bb818e658a15ce15df",
      "988315618afc4059a0c9f09558ecb62d",
      "ee15286dfa5c42cdb95ba884f0e9f4ae",
      "5b7b9ca070d649b9b4ec95cafad3b01d",
      "52bdf64a96d044b986657edb7e475929",
      "fd9ec851fd44467f97b837bac90ca7dd",
      "19c26beecd49465e81018e4f4a08d425",
      "4b92c06505124f5d9819071b852589e0",
      "a578ffba734d40c289929bd532c831c2",
      "af11cf46b77d4b469186c63addd433cb"
     ]
    },
    "id": "DeTbWyeUmJj-",
    "outputId": "ca65479e-48a7-44e3-f47a-22bdbd3c7797"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2b8ac4af7d340a190a6e11c437107ba",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = []\n",
    "\n",
    "for thr in tqdm(thrs):\n",
    "    val[\"pred_lr_tf_idf_best\"] = (val[\"pred_lr_tf_idf_proba\"] > thr) * 1\n",
    "    result.append((thr, f1_score(val[\"toxic\"], val[\"pred_lr_tf_idf_best\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bba8ff7-cb04-4ae2-8ea3-eddd1c0425dd",
   "metadata": {},
   "source": [
    "Выведем значение порога, обеспечивающего получение максимальное значение целевой метрики. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "21e93f7b-7fb2-4d1a-83d1-a566da5d9734",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "72MZS2Ypn7DW",
    "outputId": "9ad15d23-9bbd-40fb-e150-729428396f25"
   },
   "outputs": [
    {
     "data": {},
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = pd.DataFrame(result, columns=[\"thr\", \"f1\"])\n",
    "\n",
    "thr_best = t.loc[t[\"f1\"] == t[\"f1\"].max(), \"thr\"].values[0]\n",
    "\n",
    "t[t[\"f1\"] == t[\"f1\"].max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50cfe04-348d-4ec8-b721-85c0238455cb",
   "metadata": {},
   "source": [
    "Полученное значение лучше \"ненастроенного\" на 0,5%.\n",
    "\n",
    "В дальнейшем будем использовать его для расчета целевой метрики на тестовой подвыборке."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8453ab68-52e6-41ae-b2aa-d36d6524b8e1",
   "metadata": {},
   "source": [
    "## Тестирование лучшей модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09677e53-3609-4e8f-8c2e-622edc958eaf",
   "metadata": {},
   "source": [
    "Проведем расчет целевой метрики F1 на тестовой подвыборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "21fbe64f-273b-43b9-a658-2040d8086177",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"pred_lr_tf_idf_proba\"] = np.NaN\n",
    "test[\"pred_lr_tf_idf_proba\"] = 1 - model_lr_tf_idf.predict_proba(test_tf_idf)\n",
    "test[\"pred_lr_tf_idf_best\"] = (test[\"pred_lr_tf_idf_proba\"] > thr_best) * 1\n",
    "f1_score(test[\"toxic\"], test[\"pred_lr_tf_idf_best\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56624c66-ebb1-4615-ba20-a73bbdd61eca",
   "metadata": {},
   "source": [
    "Полученное значение выше заданного в условии задания на 2,5%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9f76a2-3ce3-46e1-ac2a-b05028ba6052",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270d4529-a74a-4c5d-94d5-b3f7f27614f7",
   "metadata": {},
   "source": [
    "Для достижения поставленной условием задания цели решены следующие задачи:\n",
    "1. Загружены и исследованы данные;\n",
    "1. Проведена очистка незакодированного текста от лишних символов и стоп-слов;\n",
    "1. Определены признаки TF-IDF;\n",
    "1. Сформированы emedings при помощи предобученной модели BERT из стандартной библиотеки \"distilbert-base-uncased\"; \n",
    "1. Обучены на полученных признаках модели логистической регрессии (LR) и CatBoost (CB);\n",
    "1. Использована метрика ROC-AUC для определения лучшего сочетание модели и признаков. \n",
    "Получено, что для обученной на признаках TF-IDF модели LR указанная метрика имеет наивысшее значение, равное 84,5%;\n",
    "1. Для указанной модели выбран порог, обеспечивающий максимизацию значения метрики F1. \n",
    "\n",
    "В результате работы разработана модель LR, определяющая токсичные комментарии, со значением метрики F1, равным 77,5%, что лучше заданного в условии порога на 2,5%.\n",
    "Разработанная модель может быть использована для отправки токсичных комментариев на модерацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ea63ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 80739,
    "start_time": "2022-08-17T16:30:07.787Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
