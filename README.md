|№|Название проекта|Краткое описание|Основные используемые инструменты|
|--|--|--|--|
|01.|--|--|--|
|02.|--|--|--|
|03.|--|--|--|
|04.|--|--|--|
|05.|--|--|--|
|06.|--|--|--|
|07.|[Обучение с учителем](https://github.com/DEli-26/DS_Practicum/tree/main/07_churn)|Решается задача классификации клиентов, склонных к оттоку. Проведен анализ корреляции признаков, на основе которого проведена их оптимизация. Рассмотрены модели дерева решений, случайного леса и логистической регрессии. Проведен выбор гиперпараметров для достижения лучших показателей метрики ROC-AUC. Рассмотрена возможность компенсации дисбаланса классов методами upsampling и downsampling. Выполнен выбор лучшего порогового значения для использования метрики F1.|numpy, pandas, matplotlib, seaborn, sklearn, phik, DecisionTreeClassifier, RandomForestClassifier, LogisticRegression|
|08.|[Выбор локации для скважины](https://github.com/DEli-26/DS_Practicum/tree/main/08_resources)|Решается задача регрессии по выбору одного из трех регионов для перспективной разработки. Проведен подробный EDA, обнаружена сильная корреляция одного из признаков с целевым. При помощи bootstrap модели линейной регрессии  определен лучший регион. Использована метрика RMSE.|numpy, pandas, matplotlib, seaborn, sklearn, phik, LinearRegression|
|09.|[Сборный Проект №2](https://github.com/DEli-26/DS_Practicum/tree/main/09_mining)|Решается задача регрессии для предсказания эффективности технологического процесса обработки руды. Проведен подробный EDA и анализ корелляции признаков. Использованы модели линейной регрессии, дерева решений и случайного леса. При помощи кроссвалидации показано, что исключение большей части признаков из рассмотрения позволяет повысить интерпретируемость и качество предсказания модели линейной регрессии. Использована метрика SMAPE.|numpy, pandas, matplotlib, seaborn, sklearn, phik, LinearRegression, RandomForestRegressor, LinearRegression|
|10.|[Защита персональных данных клиентов](https://github.com/DEli-26/DS_Practicum/tree/main/10_matrix)|Аналитически решается задача выбора оптимального метода шифрования данных. Предложенный подход проверен при попощи линейной регрессии. Проведен подробный EDA.|numpy, pandas, matplotlib, sklearn, LinearRegression|
|11.|[Определение стоимости автомобилей](https://github.com/DEli-26/DS_Practicum/tree/main/11_boosting)|Решается задача регрессии определения стоимости автомобилей методами градиентного бустинга. Проведен подробный EDA. Рассмотрены модели LightGBM, Catboost и линейной регрессии. В качестве ключевых метрик использованы RMSE, а также время предсказания и обучения моделей.|numpy, pandas, matplotlib, seaborn, sklearn, LGBMRegressor, CatBoostRegressor, LinearRegression|
|12.|[Временные ряды](https://github.com/DEli-26/DS_Practicum/tree/main/12_timeseries)|Решается задача предсказания количество заказов такси. Исследованы сезонность и тренд для формирования списка фичей. Предложено аналитичисекое решение задачи и проведено его сравнение с моделями линейной регрессии, Catboost и Prophet. Используемая метрика RMSE.|numpy, pandas, matplotlib, seaborn, sklearn, seasonal_decompose, LinearRegression, CatBoostRegressor, Prophet|
|13.|[Проект для «Викишоп» с BERT](https://github.com/DEli-26/DS_Practicum/tree/main/13_class_toxic_text_BERT)|Решается задача классификации токсичных комментариев с созданием фичей при помощи TF-IDF и DistilBERT. Сравнение с внутренней векторизацией в Catboost. Используемые метрики ROC-AUC и F1.|numpy, pandas, sklearn, LogisticRegression, CatBoostClassifier, torch, transformers, CUDA|
|14.|--|--|--|
|15.|--|--|--|
|16.|--|--|--|
|17.|--|--|--|
|18.|--|--|--|
|19.|--|--|--|
