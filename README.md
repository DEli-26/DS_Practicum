|№|Название проекта|Краткое описание|Основные используемые инструменты|
|--|--|--|--|
|01.|--|--|--|
|02.|--|--|--|
|03.|--|--|--|
|04.|--|--|--|
|05.|--|--|--|
|06.|--|--|--|
|07.|--|--|--|
|08.|--|--|--|
|09.|[Сборный Проект №2](https://github.com/DEli-26/DS_Practicum/tree/main/09_mining)|Решается задача регрессии. Проведен подробный EDA и анализ корелляции признаков. Использованы модели линейной регрессии, дерева решений и случайного леса. При помощи кроссвалидации показано, что исключение большей части признаков из рассмотрения позволяет повысить интерпретируемость и качество предсказания модели линейной регрессии. Использована метрика SMAPE.|numpy, pandas, matplotlib, sklearn, phik,  LinearRegression, RandomForestRegressor, LinearRegression|
|10.|[Защита персональных данных клиентов](https://github.com/DEli-26/DS_Practicum/tree/main/10_matrix)|Аналитически решается задача выбора оптимального метода шифрования данных. Предложенный подход проверен при попощи линейной регрессии. Проведен подробный EDA.|numpy, pandas, matplotlib, sklearn, LinearRegression|
|11.|[Определение стоимости автомобилей](https://github.com/DEli-26/DS_Practicum/tree/main/11_boosting)|Решается задача регрессии методами градиентного бустинга. Проведен подробный EDA. Рассмотрены модели LightGBM, Catboost и линейной регрессии. В качестве ключевых метрик использованы RMSE, а также время предсказания и обучения моделей.|numpy, pandas, matplotlib, seaborn, sklearn, LGBMRegressor, CatBoostRegressor, LinearRegression|
|12.|[Временные ряды](https://github.com/DEli-26/DS_Practicum/tree/main/12_timeseries)|Решается задача предсказания временных рядов. Исследованы сезонность и тренд для формирования списка фичей. Предложено аналитичисекое решение задачи и проведено его сравнение с моделями линейной регрессии, Catboost и Prophet. Используемая метрика RMSE.|numpy, pandas, matplotlib, seaborn, sklearn, seasonal_decompose, LinearRegression, CatBoostRegressor, Prophet|
|13.|[Проект для «Викишоп» с BERT](https://github.com/DEli-26/DS_Practicum/tree/main/class_toxic_text_BERT)|Классификация текстов с созданием фичей при помощи TF-IDF и DistilBERT. Сравнение с внутренней векторизацией в Catboost. Используемые метрики ROC-AUC и F1.|numpy, pandas, sklearn, LogisticRegression, CatBoostClassifier, torch, transformers, CUDA|
|14.|--|--|--|
|15.|--|--|--|
|16.|--|--|--|
|17.|--|--|--|
|18.|--|--|--|
|19.|--|--|--|
